# UCSD-Audio

Cite: http://extrasensory.ucsd.edu/#paper.Vaizman2017a

A dataset for behavioral context recognition in-the-wild from mobile sensors:
-Large scale: over 300k examples (minutes) from 60 users.
-Everyday devices: sensors from smartphone (iPhone/Android) and smartwatch.
-Diverse sensors: heterogeneous measurements from different sensors.
-In-the-Wild: data was collected from users that were engaged in their regular natural behavior.
-Rich context: annotations are combinations of context labels from a large vocabulary.
-Publicly available: everyone is invited to download the dataset for free and use it (conditioned on citing our original paper).

**This dataset was collected in 2015-2016 by Yonatan Vaizman and Katherine Ellis with the supervision of professor Gert Lanckriet.
Department of Electrical and Computer Engineering, University of California, San Diego.
Original publication: "Recognizing Detailed Human Context In-the-Wild from Smartphones and Smartwatches".

**Research use only**
